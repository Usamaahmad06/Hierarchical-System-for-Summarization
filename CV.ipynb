{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1wYWp9aG19G0KAZ5TIyDgBjvX41ArDX8C",
      "authorship_tag": "ABX9TyMgQZKhgRTiW9Ty2Op/ZUu3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Usamaahmad06/Hierarchical-System-for-Summarization/blob/main/CV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7Ktlp3eAyk8",
        "outputId": "931d4d75-4676-455d-c352-a845a8f6b2c0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################ PARAMETERS ########################\n",
        "path = '/content/drive/My Drive/myData'  # Update this path if needed\n",
        "testRatio = 0.2\n",
        "valRatio = 0.2\n",
        "imageDimensions = (32, 32, 3)\n",
        "batchSizeVal = 50\n",
        "epochsVal = 1\n",
        "stepsPerEpochVal = 2000\n",
        "####################################################"
      ],
      "metadata": {
        "id": "rKWNH7w-A2jF"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### IMPORTING DATA/IMAGES FROM FOLDERS\n",
        "count = 0\n",
        "images = []     # LIST CONTAINING ALL THE IMAGES\n",
        "classNo = []    # LIST CONTAINING ALL THE CORRESPONDING CLASS ID OF IMAGES\n",
        "myList = os.listdir(path)\n",
        "print(\"Total Classes Detected:\",len(myList))\n",
        "noOfClasses = len(myList)\n",
        "print(\"Importing Classes .......\")\n",
        "for x in range (0,noOfClasses):\n",
        "    myPicList = os.listdir(path+\"/\"+str(x))\n",
        "    for y in myPicList:\n",
        "        curImg = cv2.imread(path+\"/\"+str(x)+\"/\"+y)\n",
        "        curImg = cv2.resize(curImg,(32,32))\n",
        "        images.append(curImg)\n",
        "        classNo.append(x)\n",
        "    print(x,end= \" \")\n",
        "print(\" \")\n",
        "print(\"Total Images in Images List = \",len(images))\n",
        "print(\"Total IDS in classNo List= \",len(classNo))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "GWglU4jiBXWh",
        "outputId": "e1fc3671-5e0c-40b6-b913-3c2447423eb7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/My Drive/myData'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-e9fdfe88753b>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m     \u001b[0;31m# LIST CONTAINING ALL THE IMAGES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclassNo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m    \u001b[0;31m# LIST CONTAINING ALL THE CORRESPONDING CLASS ID OF IMAGES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmyList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total Classes Detected:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnoOfClasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/myData'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### CONVERT TO NUMPY ARRAY\n",
        "images = np.array(images)\n",
        "classNo = np.array(classNo)\n",
        "print(images.shape)"
      ],
      "metadata": {
        "id": "-aGQ7BnVBlks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### SPLITTING THE DATA\n",
        "X_train,X_test,y_train,y_test = train_test_split(images,classNo,test_size=testRatio)\n",
        "X_train,X_validation,y_train,y_validation = train_test_split(X_train,y_train,test_size=valRatio)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(X_validation.shape)"
      ],
      "metadata": {
        "id": "HlRsZgvWCYuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### PLOT BAR CHART FOR DISTRIBUTION OF IMAGES\n",
        "numOfSamples= []\n",
        "for x in range(0,noOfClasses):\n",
        "    #print(len(np.where(y_train==x)[0]))\n",
        "    numOfSamples.append(len(np.where(y_train==x)[0]))\n",
        "print(numOfSamples)\n"
      ],
      "metadata": {
        "id": "jJU8K1NXChap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.bar(range(0,noOfClasses),numOfSamples)\n",
        "plt.title(\"No of Images for each Class\")\n",
        "plt.xlabel(\"Class ID\")\n",
        "plt.ylabel(\"Number of Images\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PY4buOckChND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### PREPOSSESSING FUNCTION FOR IMAGES FOR TRAINING\n",
        "def preProcessing(img):\n",
        "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "    img = cv2.equalizeHist(img)\n",
        "    img = img/255\n",
        "    return img\n",
        "# img = preProcessing(X_train[30])\n",
        "# img = cv2.resize(img,(300,300))\n",
        "# cv2.imshow(\"PreProcesssed\",img)\n",
        "# cv2.waitKey(0)\n",
        "\n",
        "X_train= np.array(list(map(preProcessing,X_train)))\n",
        "X_test= np.array(list(map(preProcessing,X_test)))\n",
        "X_validation= np.array(list(map(preProcessing,X_validation)))"
      ],
      "metadata": {
        "id": "wdrIfp9hCgpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### RESHAPE IMAGES\n",
        "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2],1)\n",
        "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2],1)\n",
        "X_validation = X_validation.reshape(X_validation.shape[0],X_validation.shape[1],X_validation.shape[2],1)"
      ],
      "metadata": {
        "id": "RbkCXgDZCucT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### IMAGE AUGMENTATION\n",
        "dataGen = ImageDataGenerator(width_shift_range=0.1,\n",
        "                             height_shift_range=0.1,\n",
        "                             zoom_range=0.2,\n",
        "                             shear_range=0.1,\n",
        "                             rotation_range=10)\n",
        "dataGen.fit(X_train)"
      ],
      "metadata": {
        "id": "zmVo47uwCuU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### ONE HOT ENCODING OF MATRICES\n",
        "y_train = to_categorical(y_train,noOfClasses)\n",
        "y_test = to_categorical(y_test,noOfClasses)\n",
        "y_validation = to_categorical(y_validation,noOfClasses)"
      ],
      "metadata": {
        "id": "jQZBlYtKCuNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### CREATING THE MODEL\n",
        "def myModel():\n",
        "    noOfFilters = 60\n",
        "    sizeOfFilter1 = (5,5)\n",
        "    sizeOfFilter2 = (3, 3)\n",
        "    sizeOfPool = (2,2)\n",
        "    noOfNodes= 500\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add((Conv2D(noOfFilters,sizeOfFilter1,input_shape=(imageDimensions[0],\n",
        "                      imageDimensions[1],1),activation='relu')))\n",
        "    model.add((Conv2D(noOfFilters, sizeOfFilter1, activation='relu')))\n",
        "    model.add(MaxPooling2D(pool_size=sizeOfPool))\n",
        "    model.add((Conv2D(noOfFilters//2, sizeOfFilter2, activation='relu')))\n",
        "    model.add((Conv2D(noOfFilters//2, sizeOfFilter2, activation='relu')))\n",
        "    model.add(MaxPooling2D(pool_size=sizeOfPool))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(noOfNodes,activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(noOfClasses, activation='softmax'))\n",
        "\n",
        "    model.compile(Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = myModel()\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "vuEVBkGVCuF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### STARTING THE TRAINING PROCESS\n",
        "history = model.fit_generator(dataGen.flow(X_train,y_train,\n",
        "                                 batch_size=batchSizeVal),\n",
        "                                 steps_per_epoch=stepsPerEpochVal,\n",
        "                                 epochs=epochsVal,\n",
        "                                 validation_data=(X_validation,y_validation),\n",
        "                                 shuffle=1)"
      ],
      "metadata": {
        "id": "PO946zwUCt-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### PLOT THE RESULTS\n",
        "plt.figure(1)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['training','validation'])\n",
        "plt.title('Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.figure(2)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.legend(['training','validation'])\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ie8E9dr6DESw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### EVALUATE USING TEST IMAGES\n",
        "score = model.evaluate(X_test,y_test,verbose=0)\n",
        "print('Test Score = ',score[0])\n",
        "print('Test Accuracy =', score[1])"
      ],
      "metadata": {
        "id": "FiMcF879DEJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### SAVE THE TRAINED MODEL\n",
        "pickle_out= open(\"model_trained.p\", \"wb\")\n",
        "pickle.dump(model,pickle_out)\n",
        "pickle_out.close()"
      ],
      "metadata": {
        "id": "k5gLbAiSDQIi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}